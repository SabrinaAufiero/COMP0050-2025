{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af319573-1519-4c1e-b678-2f2fa27f3df7",
   "metadata": {},
   "source": [
    "# The classic cats vs. dogs problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7558955b-63e9-4f40-8343-ab353b0fb0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Subset, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "114e5167-330e-4095-b6ba-b07ed2adbe15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Check if GPU is available for faster training\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a95e18-44f2-436b-95d9-e641a46a1099",
   "metadata": {},
   "source": [
    "https://www.cs.toronto.edu/~kriz/cifar.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62acbeba-6ea1-495e-96f5-a7e30f9ec728",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preparation\n",
    "\n",
    "# We use the CIFAR-10 dataset, but we will filter it to only include cats and dogs.\n",
    "# In CIFAR-10, the class indices are:\n",
    "#   3: cat\n",
    "#   5: dog\n",
    "\n",
    "# Define transforms: convert images to tensors and normalize them.\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalize each channel\n",
    "])\n",
    "\n",
    "# Download CIFAR-10 training and test sets\n",
    "train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset  = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# Function to filter the dataset: only keep indices with label 3 (cat) or 5 (dog)\n",
    "def filter_cat_dog(dataset):\n",
    "    indices = [i for i, (_, label) in enumerate(dataset) if label in [3, 5]]\n",
    "    return Subset(dataset, indices)\n",
    "\n",
    "# Filter training and test datasets\n",
    "train_subset = filter_cat_dog(train_dataset)\n",
    "test_subset  = filter_cat_dog(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e561886f-4338-430d-ae41-df0bfea929ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a custom dataset to re-map the labels:\n",
    "#   Original label 3 (cat) -> 0\n",
    "#   Original label 5 (dog) -> 1\n",
    "\n",
    "class CatDogDataset(Dataset):\n",
    "    def __init__(self, subset):\n",
    "        self.subset = subset\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img, label = self.subset[index]\n",
    "        # Remap labels: cat -> 0, dog -> 1\n",
    "        label = 0 if label == 3 else 1\n",
    "        return img, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dcafbaf1-c979-4e76-aa56-827144727311",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap the subsets into our custom dataset\n",
    "train_data = CatDogDataset(train_subset)\n",
    "test_data  = CatDogDataset(test_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04470f76-b73e-4591-a957-e6827d87a1d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.CatDogDataset object at 0x158a4cd10>\n"
     ]
    }
   ],
   "source": [
    "print(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3decbf39-3da5-4908-8054-7ad4bc007ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoaders for training and testing\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "test_loader  = DataLoader(test_data, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582db640-0729-4e53-86bc-37b4c2709763",
   "metadata": {},
   "source": [
    "A Convolutional Neural Network (CNN) is a specialized type of neural network particularly effective for processing data that has a grid-like structure, such as images. These layers use filters (kernels) to scan the image and extract features like edges, textures, and shapes. They slide over the input, performing convolution operations that capture local patterns.\n",
    "\n",
    "They are very efficient at recognizing patterns and hierarchies in images. Early layers capture simple features (like edges), and deeper layers capture more complex patterns (like shapes or even objects).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "edda920f-4622-42d6-8ba1-f8e590356eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CNN Architecture\n",
    "\n",
    "# This CNN is designed for 32x32 images (the CIFAR-10 image size)\n",
    "\n",
    "class CatDogCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CatDogCNN, self).__init__()\n",
    "        # Convolutional layers\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            # First convolution block\n",
    "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1),  # 32x32x32\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),                                # 32x16x16\n",
    "\n",
    "            # Second convolution block\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),   # 64x16x16\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),                                # 64x8x8\n",
    "\n",
    "            # Third convolution block\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),  # 128x8x8\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)                                 # 128x4x4\n",
    "        )\n",
    "        # Fully connected layers\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Linear(128 * 4 * 4, 256),  # Flattened size: 128 channels * 4 * 4 pixels\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 2)             # Output layer: 2 classes (cat and dog)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Pass input through the convolutional layers\n",
    "        x = self.conv_layers(x)\n",
    "        # Flatten the output for the fully connected layers\n",
    "        x = x.view(x.size(0), -1)\n",
    "        # Pass through the fully connected layers\n",
    "        x = self.fc_layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61a79ad1-0f69-422a-bd8a-841c60f28ed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CatDogCNN(\n",
      "  (conv_layers): Sequential(\n",
      "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): ReLU()\n",
      "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU()\n",
      "    (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fc_layers): Sequential(\n",
      "    (0): Linear(in_features=2048, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=256, out_features=2, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the model and move it to the device (GPU or CPU)\n",
    "model = CatDogCNN().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bad1c108-2301-4b1c-b6e7-b61cee5b51dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Setup\n",
    "\n",
    "# We use CrossEntropyLoss for multi-class classification (even though we have 2 classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6fbbbd1e-b11e-48e2-8353-db2c24308d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Function\n",
    "\n",
    "def train(model, train_loader, criterion, optimizer, device, num_epochs=10):\n",
    "    model.train()  # Set model to training mode\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for images, labels in train_loader:\n",
    "            # Move data to the device\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        avg_loss = running_loss / len(train_loader)\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "09e84fde-2fba-4cde-890a-d649365d446e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation Function\n",
    "\n",
    "def evaluate(model, test_loader, device):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            # Move data to device\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            # Get the predicted class with the highest score\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "74b16149-80b7-409a-aec2-1eb5bffa86b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.6406\n",
      "Epoch [2/10], Loss: 0.5556\n",
      "Epoch [3/10], Loss: 0.5055\n",
      "Epoch [4/10], Loss: 0.4475\n",
      "Epoch [5/10], Loss: 0.4041\n",
      "Epoch [6/10], Loss: 0.3495\n",
      "Epoch [7/10], Loss: 0.2861\n",
      "Epoch [8/10], Loss: 0.2346\n",
      "Epoch [9/10], Loss: 0.1788\n",
      "Epoch [10/10], Loss: 0.1334\n",
      "Test Accuracy: 76.70%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "76.7"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train and Evaluate the Model\n",
    "\n",
    "num_epochs = 10  # For demonstration, we train for 10 epochs. In practice, you may train longer.\n",
    "train(model, train_loader, criterion, optimizer, device, num_epochs=num_epochs)\n",
    "evaluate(model, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78851a5-2043-424f-9ae8-ec1880f12735",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
